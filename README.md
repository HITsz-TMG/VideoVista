
#  VideoVista Family



<a src="https://img.shields.io/badge/cs.CV-2406.11303-b31b1b?logo=arxiv&logoColor=red" href="https://arxiv.org/abs/2406.11303"> <img src="https://img.shields.io/badge/cs.CV-2406.11303-b31b1b?logo=arxiv&logoColor=red">
</a> | 


If you appreciate our project, please consider giving us a star â­ on GitHub to stay updated with the latest developments.

## ğŸ”¥ News

**`2025.04.15`** ğŸš€ We release VideoVista-CulturalLingo, the first video evaluation benchmark designed to bridge cultural, linguistic, and domain divide in video comprehension. You can download this benchmark from [HuggingFace](https://huggingface.co/datasets/Uni-MoE/VideoVista-CulturalLingo).

**`2025.04.13`** ğŸ‰ We move the previous VideoVista from [Uni-MoE](https://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs) to here.



## :page_facing_up: Citation
If you find this project useful in your research, please consider cite:
```bibtex
@misc{li2024videovista,
      title={VideoVista: A Versatile Benchmark for Video Understanding and Reasoning}, 
      author={Yunxin Li and Xinyu Chen and Baotian Hu and Longyue Wang and Haoyuan Shi and Min Zhang},
      year={2024},
      eprint={2406.11303},
      archivePrefix={arXiv}
}
```